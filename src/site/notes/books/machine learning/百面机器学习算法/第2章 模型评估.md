---
{"dg-publish":true,"permalink":"/books/machine-learning//2/","tags":["百面机器学习"]}
---


# 模型评估

## 评估指标
- 回归
   - 平方根误差RMSE
      - $RMSE=\sqrt{\frac{\sum\limits_{i=1}^n{(y_i-\hat{y_i})^2}}{n}}$
      - 当数据中存在偏离程度非常大的离群点(Outlier)时，RMSE可能失效
         - 噪声：过滤
         - 非噪声：提高模型预测能力
         - 选择其他指标
            - 鲁棒性更好的MAPE(平均绝对百分比误差)
               $MAPE=\sum\limits_{i=1}^n\vert{\frac{y_i-\hat{y_i}}{y_i}\times{\frac{100}{n}}}\vert$
- 分类
   - 准确率
      - $Accuracy = \frac{n_{correct}}{n_{total}}$
      - 问题：正负样本比例非常不均衡时，占比大的类别成为影响准确率的最主要因素
      - 解决方法：使用平均准确率替代
   - 精确率
   - 召回率
   - F1-Score
      - $F1=\frac{2*precision*recall}{precision+recall}$
   - ROC曲线
      - $FPR=\frac{FP}{N}$
      - $TPR=\frac{TP}{P}$
      - AUC
      - 可以降低不同测试集带来的干扰
   - P-R曲线
      - 相比ROC，可以观察模型在特定测试集上的效果
- 样本距离
   - 特征通常表示为向量形式
   - 距离
	- 非严格定义的距离
		- 1-余弦相似度——方向上的相对差异
			- 不满足三角不等式
			- 词向量的余弦距离不符合三角不等 
		- KL距离(Kullback-Leibler Divergence)-相对熵
			- 计算两个分布之间的差异
			- 不满足对称性
			- 不满足三角不等式
	- 严格定义的距离
	      - 欧式距离——数值上的绝对差异
	         - 受维度影响
	         - 受量纲影响
	         - 含义模糊
	         - 当向量的模长归一化后
	            $\parallel A-B\parallel=\sqrt{2(1-\cos(A,B))}$
## A/B测试
- 为何
   - 离线评估无法完全消除过拟合的影响
   - 离线评估无法完全还原线上工程环境
      - 延迟
      - 数据丢失
      - 标签缺失
      - 其他
   - 某些商业指标无法在离线评估中计算
      - 点击率
      - 留存时长
      - pv
- 如何
   - 用户分桶
      - 独立性-同个用户只能在同一个桶
      - 无偏-userid是随机数
   - 将用户切分为实验组和对照组
      - 选取指定目标用户

## 检验方法
- Holdout检验
   - 缺点：验证集的评估指标与数据划分有很大关系
- 交叉验证
   - 消除了数据集划分引入的随机性
   - 留一法
   - 留p法
      - 组合数：$C_n^p$
      - 时间开销远高于留一法
      - 实际工程中很少使用
- 自助法
	- 样本规模比较小
	- 样本总数为n
		- 进行n次有放回随机抽样
		- 抽中为训练集
		- 未抽中的作为验证集
		- $\begin{aligned}\lim_{n\to\infty}(1-\frac{1}{n})^n&=e^{\lim_{n\to\infty}n\ln(1-\frac{1}{n})}\\&=e^{\lim_{n\to\infty}\frac{\ln(1-\frac{1}{n})}{\frac{1}{n}}}\\&=e^{\lim_{n\to\infty}\frac{\frac{1}{(1-\frac{1}{n})}\times\frac{1}{n^2}}{-\frac{1}{n^2}}}\\&=e^{\lim_{n\to\infty}\frac{-1}{1-\frac{1}{n}}}\\&=e^{-1}\\&\approx{0.368}\end{aligned}$
## 参数调优
- 是否利用之前的信息
   - 不利用
      - 网格搜索
         - 有很大概率找到全局最优
         - 十分消耗计算资源和时长
         - 优化方式
            - 搜索范围由广到窄
            - 搜索步长由大到小
            - 目标函数一般是非凸，可能错过全局最优
      - 随机搜索
         - 在搜索范围中随机选取样本点
         - 理论依据：只要样本点足够大，有很大概率找到全局最优
   - 利用
      - 贝叶斯优化算法
         - 对目标函数形状进行学习
         - 根据先验分布，假设搜集函数
         - 使用新采样点测试目标函数时，更新先验分布
         - 由后验分布给出全局最值最可能出现的位置点
         - 容易陷入局部最优
- google vizier

## 风险
- 过拟合
   - 原因
      - 模型过于复杂将噪声也学习到模型中
      - 对训练数据拟合过当
      - 泛化能力差
   - 指标表现
      - 训练集上效果好
      - 测试集上效果差
   - 降低方法
      - 加入更多训练数据
      - 降低模型复杂度
      - 增加正则化
      - 集成学习
- 欠拟合
   - 原因
      - 没有很好的捕捉到数据特征
   - 指标表现
      - 训练集上效果差
      - 测试集上效果差
   - 降低方法
      - 增加新特征
         - 因式分解机
         - 梯度提升决策树
         - Deep-crossing
      - 增加模型复杂度
         - 线性模型中增加高次项
         - 神经网络中增加层数和神经元个数
      - 减少正则化系数

