---
{"dg-publish":true,"permalink":"/books/machine-learning//12/","tags":["百面机器学习"]}
---


# 集成学习

## boosting
- 串行
- 强依赖
- 减小偏差
- 聚焦基分类器分错样本
- GBDT
   - 优点
      - 预测阶段可并行化
      - 在分布稠密的数据集上泛化能力和表达都很好
      - 决策树具有较好的解释性和鲁棒性
   - 缺点
      - 高维稀疏数据集上表现不如支持向量机或神经网络
      - 不适合文本分类特征
      - 训练需要串行
- XGBoost
   - 高效实现了GBDT
      - 决策树构建阶段加入正则项
      - 损失函数进行了二阶泰勒展开
      - 支持出了CART的多种基分类器
      - 支持对数据采样
      - 支持缺失值处理

## bagging
- 并行
- 无强依赖
- 减小方差
- 基分类器
   - 不稳定的分类器：对样本敏感
   - 不适合使用的基分类器
      - 线性分类器
      - K近邻

## 步骤
- 寻找误差相互独立的基分类器
   - 决策树
      - 方便调整样本权重
      - 表达和泛化能力可以通过调节树的层数来实现
      - 样本扰动对决策树影响较大
      - 叶节点分裂时随机选择特征子集引入了随机性
   - 神经网络
      - 随机性
         - 神经元数量
         - 连接方式
         - 网络层数
         - 初始权值
- 训练基分类器
- 合并基分类器结果
   - voting
   - stacking